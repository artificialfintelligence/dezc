{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fde351c-3c32-43df-ad82-09dd8c7e3efa",
   "metadata": {},
   "source": [
    "# Working with RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfac4af3-c242-4978-a543-83f97247ca99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2302514-0717-42d6-aa7c-dc61c156a35b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/27 19:10:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"NYTaxi\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b86ba71-ea15-4c51-8fa2-ba637b58d937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa7dfc-4345-4b28-879f-399d6f86d2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "We want to implement the following, but this time with RDDs instead of the convenient API that DataFrames provide.\n",
    "\n",
    "``` sql\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba543e2-f041-4db9-986c-0960b311e933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f355d78-7048-4b49-93d2-9179fddf5405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 13, 38, 16), store_and_fwd_flag='N', RatecodeID=1, PULocationID=74, DOLocationID=130, passenger_count=1, trip_distance=12.77, fare_amount=36.0, extra=0.0, mta_tax=0.5, tip_amount=2.05, tolls_amount=6.12, ehail_fee=None, improvement_surcharge=0.3, total_amount=44.97, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), lpep_dropoff_datetime=datetime.datetime(2020, 1, 20, 15, 46), store_and_fwd_flag=None, RatecodeID=None, PULocationID=67, DOLocationID=39, passenger_count=None, trip_distance=8.0, fare_amount=29.9, extra=2.75, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=33.45, payment_type=None, trip_type=None, congestion_surcharge=None),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), lpep_dropoff_datetime=datetime.datetime(2020, 1, 15, 20, 31, 18), store_and_fwd_flag='N', RatecodeID=1, PULocationID=260, DOLocationID=157, passenger_count=1, trip_distance=1.27, fare_amount=7.0, extra=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), lpep_dropoff_datetime=datetime.datetime(2020, 1, 5, 16, 40, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=82, DOLocationID=83, passenger_count=1, trip_distance=1.25, fare_amount=7.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), lpep_dropoff_datetime=datetime.datetime(2020, 1, 29, 19, 31, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=42, passenger_count=1, trip_distance=1.84, fare_amount=8.0, extra=1.0, mta_tax=0.5, tip_amount=2.94, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.74, payment_type=1, trip_type=1, congestion_surcharge=0.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd512192-3524-4edb-84ff-e9dedecc183c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the columns we need\n",
    "rdd = df_green \\\n",
    "    .select(\"lpep_pickup_datetime\", \"PULocationID\", \"total_amount\") \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ba18a7-5b84-4298-b46e-5466aa08086b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876895bb-e442-4397-aa97-82fa38e6fae2",
   "metadata": {},
   "source": [
    "## Implementing the `WHERE` Clause with `filter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f37fd6-737f-47cc-ab96-f4c0f68c37a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[16] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime(year=2020, month=1, day=1)\n",
    "\n",
    "def filter_date_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start_date\n",
    "\n",
    "rdd \\\n",
    "    .filter(filter_date_outliers)\n",
    "    # Or just\n",
    "    # .filter(lambda row: row.lpep_pickup_datetime >= start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76103bf-bc20-4698-b443-063f83681a82",
   "metadata": {},
   "source": [
    "## Preparing for Grouping with `map()` and Implementing the `GROUP BY` Clause with `reduce()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeedd0fc-b5e1-44f7-a7c3-ce9535b9470b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row = rdd.take(1)[0]\n",
    "sample_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59434d9a-834e-4065-9e89-5382177a5130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 23, 13, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only want the hour (see `date_trunc` in the SQL query)\n",
    "sample_row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39461a10-23bd-46f5-ba43-b350da254060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_for_grouping(row):\n",
    "    # (hour, zone) comprises our composite key \n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    \n",
    "    # (amount, count) makes up our value\n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    \n",
    "    key = (hour, zone)\n",
    "    value = (amount, count)\n",
    "    \n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a737ae7e-a71d-4ef9-a7f8-b0b712e50655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 23, 13, 0), 74), (44.97, 1)),\n",
       " ((datetime.datetime(2020, 1, 20, 15, 0), 67), (33.45, 1)),\n",
       " ((datetime.datetime(2020, 1, 15, 20, 0), 260), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 5, 16, 0), 82), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 29, 19, 0), 166), (12.74, 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_date_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d928b857-109e-432f-9538-f7840bb1055d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_calc(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63cc00a-6d7b-43fe-af2a-71f669d10425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 15, 20, 0), 260), (163.90000000000003, 14)),\n",
       " ((datetime.datetime(2020, 1, 29, 19, 0), 166), (695.0099999999999, 45)),\n",
       " ((datetime.datetime(2020, 1, 16, 8, 0), 41), (736.1399999999996, 54)),\n",
       " ((datetime.datetime(2020, 1, 4, 20, 0), 129), (583.27, 38)),\n",
       " ((datetime.datetime(2020, 1, 2, 8, 0), 66), (197.69, 10))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_date_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(custom_calc) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac870b3-bbad-40ba-a507-a926403e8ed1",
   "metadata": {},
   "source": [
    "That took considerably longer, because it had to go through and aggregate the entire dataset! Now let's just format the output (the nested tuples aren't very nice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d8d3a5-3c67-437a-8c08-d5d6a9c391e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return (row[0][0], row[0][1], row[1][0], row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9163e51a-d1bf-4e85-98d8-2f8e8df96e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2020, 1, 15, 20, 0), 260, 163.90000000000003, 14),\n",
       " (datetime.datetime(2020, 1, 29, 19, 0), 166, 695.0099999999999, 45),\n",
       " (datetime.datetime(2020, 1, 16, 8, 0), 41, 736.1399999999996, 54),\n",
       " (datetime.datetime(2020, 1, 4, 20, 0), 129, 583.27, 38),\n",
       " (datetime.datetime(2020, 1, 2, 8, 0), 66, 197.69, 10)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_date_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(custom_calc) \\\n",
    "    .map(unwrap) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b25c3d-3f8f-4be6-b31c-0cca3851733a",
   "metadata": {},
   "source": [
    "And finally turn it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1cf4b8-5384-4d48-8b48-9a1449afde81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------------+---+\n",
      "|                 _1| _2|                _3| _4|\n",
      "+-------------------+---+------------------+---+\n",
      "|2020-01-15 20:00:00|260|163.90000000000003| 14|\n",
      "|2020-01-29 19:00:00|166| 695.0099999999999| 45|\n",
      "|2020-01-16 08:00:00| 41| 736.1399999999996| 54|\n",
      "|2020-01-04 20:00:00|129|            583.27| 38|\n",
      "|2020-01-02 08:00:00| 66|            197.69| 10|\n",
      "|2020-01-03 09:00:00| 61|            142.21|  9|\n",
      "|2020-01-17 21:00:00|236|              33.6|  4|\n",
      "|2020-01-12 12:00:00| 82|            290.41| 14|\n",
      "|2020-01-28 16:00:00|197| 831.4399999999998| 18|\n",
      "|2020-01-10 22:00:00| 95| 407.7100000000002| 37|\n",
      "|2020-01-10 01:00:00|215|            109.69|  2|\n",
      "|2020-01-07 18:00:00| 25| 554.2900000000001| 37|\n",
      "|2020-01-18 07:00:00| 55|              48.3|  1|\n",
      "|2020-01-28 09:00:00|166| 473.0200000000002| 36|\n",
      "|2020-01-12 15:00:00| 82| 265.7900000000001| 29|\n",
      "|2020-01-10 20:00:00| 66|            405.88| 21|\n",
      "|2020-01-31 15:00:00| 43|345.58000000000004| 19|\n",
      "|2020-01-31 21:00:00| 41| 588.1600000000001| 40|\n",
      "|2020-01-25 18:00:00| 65| 457.0600000000001| 28|\n",
      "|2020-01-26 14:00:00|166| 301.7900000000001| 26|\n",
      "+-------------------+---+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_date_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(custom_calc) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60d420-96fb-4f24-a0ac-de59050e9471",
   "metadata": {},
   "source": [
    "Oh no! Not surprisingly, we have lost our column names and schema! Fret not, as we will restore them with named tuples 😎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9be64e-2219-4d0f-bec2-2534a5419f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
